{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:14.905006Z",
     "start_time": "2025-06-15T18:35:14.900098Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from seq2seq_translation.datasets.datasets import LanguagePairsDatasets\n",
    "from seq2seq_translation.sentence_pairs_dataset import SentencePairsDataset\n",
    "from seq2seq_translation.tokenization.sentencepiece_tokenizer import SentencePieceTokenizer\n",
    "from seq2seq_translation.run import _fix_model_state_dict"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "torch.random.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:14.914888Z",
     "start_time": "2025-06-15T18:35:14.909290Z"
    }
   },
   "id": "5176f06e6aa5f6b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "source_tokenizer = SentencePieceTokenizer(model_prefix='/Users/adam.amster/Downloads/30000/en30000')\n",
    "target_tokenizer = SentencePieceTokenizer(model_prefix='/Users/adam.amster/Downloads/30000/fr30000')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:14.956018Z",
     "start_time": "2025-06-15T18:35:14.923401Z"
    }
   },
   "id": "5942c27f80686dae",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ['DEVICE'] = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:14.963284Z",
     "start_time": "2025-06-15T18:35:14.961574Z"
    }
   },
   "id": "d49393923246e455",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def construct_test_dset():\n",
    "\ttest_datasets = LanguagePairsDatasets(\n",
    "\t\t\tout_dir=Path('/Users/adam.amster/seq2seq_translation/datasets/wmt14_test'),\n",
    "\t\t\tsource_lang='en',\n",
    "\t\t\ttarget_lang='fr',\n",
    "\t\t\tis_test=True\n",
    "\t)\n",
    "\t\n",
    "\ttest_dset = SentencePairsDataset(\n",
    "\t\tdatasets=test_datasets,\n",
    "\t\tidxs=np.arange(len(test_datasets)),\n",
    "\t\tsource_tokenizer=source_tokenizer,\n",
    "\t\ttarget_tokenizer=target_tokenizer,\n",
    "\t\tmax_length=None,\n",
    "        eos_token_id=source_tokenizer.eot_idx,\n",
    "        pad_token_id=source_tokenizer.pad_idx,\n",
    "        add_bos_token_id=True,\n",
    "        bos_token_id=source_tokenizer.processor.bos_id()\n",
    "\t)\n",
    "\treturn test_dset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:14.970730Z",
     "start_time": "2025-06-15T18:35:14.968536Z"
    }
   },
   "id": "fd372758075226e6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "test_dset = construct_test_dset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:20.626978Z",
     "start_time": "2025-06-15T18:35:14.976313Z"
    }
   },
   "id": "92f8ac9a2a42c9fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3b7c142aa304b08877e2ef500fd1cc6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "from seq2seq_translation.models.attention.attention import AttentionType\n",
    "from seq2seq_translation.models.rnn import EncoderRNN, AttnDecoderRNN, EncoderDecoderRNN\n",
    "\n",
    "\n",
    "def construct_model_attention():\n",
    "\tencoder = EncoderRNN(\n",
    "\t\tinput_size=source_tokenizer.processor.vocab_size(),\n",
    "\t\thidden_size=1000,\n",
    "\t\tbidirectional=True,\n",
    "\t\tpad_idx=source_tokenizer.processor.pad_id(),\n",
    "\t\tembedding_dim=1000,\n",
    "\t\tnum_layers=4,\n",
    "\t)\n",
    "\n",
    "\tdecoder = AttnDecoderRNN(\n",
    "\t\thidden_size=1000,\n",
    "\t\tattention_size=1000,\n",
    "\t\toutput_size=target_tokenizer.processor.vocab_size(),\n",
    "\t\tencoder_bidirectional=True,\n",
    "\t\tmax_len=200,\n",
    "\t\tattention_type=AttentionType.CosineSimilarityAttention,\n",
    "\t\tencoder_output_size=encoder.output_size,\n",
    "\t\tpad_idx=source_tokenizer.processor.pad_id(),\n",
    "\t\tnum_embeddings=target_tokenizer.processor.vocab_size(),\n",
    "\t\tsos_token_id=source_tokenizer.processor.bos_id(),\n",
    "\t\tembedding_dim=1000,\n",
    "\t\tnum_layers=4,\n",
    "\t\teos_token_id=target_tokenizer.processor.eos_id()\n",
    "\t)\n",
    "\t\n",
    "\tencoder.load_state_dict(\n",
    "\t\t_fix_model_state_dict(torch.load('/Users/adam.amster/Downloads/attention/encoder.pt', map_location='cpu'))\n",
    "\t)\n",
    "\tdecoder.load_state_dict(\n",
    "\t\t_fix_model_state_dict(torch.load('/Users/adam.amster/Downloads/attention/decoder.pt', map_location='cpu'))\n",
    "\t)\n",
    "\tencoder_decoder = EncoderDecoderRNN(\n",
    "\t\tencoder=encoder,\n",
    "\t\tdecoder=decoder,\n",
    "\t)\n",
    "\tencoder_decoder.eval()\n",
    "\treturn encoder_decoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:20.646155Z",
     "start_time": "2025-06-15T18:35:20.640529Z"
    }
   },
   "id": "6cdd466198dd3557",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "encoder_decoder = construct_model_attention()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:21.796148Z",
     "start_time": "2025-06-15T18:35:20.654147Z"
    }
   },
   "id": "ad0b0f1e96d6b18",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "def get_test_dset_examples():\n",
    "\tshort = [x for x in test_dset if  10 <= len(x[0]) <= 20]\n",
    "\treturn short"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:21.805619Z",
     "start_time": "2025-06-15T18:35:21.803445Z"
    }
   },
   "id": "f153cd66edc93261",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "short_examples = get_test_dset_examples()\n",
    "rand_idxs = torch.randint(low=0, high=len(short_examples), size=(4,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:22.215965Z",
     "start_time": "2025-06-15T18:35:21.812398Z"
    }
   },
   "id": "878901c00a028194",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:22.225558Z",
     "start_time": "2025-06-15T18:35:22.221879Z"
    }
   },
   "cell_type": "code",
   "source": "[source_tokenizer.processor.id_to_piece(x.item()) for x in short_examples[rand_idxs[0]][0]]",
   "id": "8728f5e8f1f60d9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁But',\n",
       " '▁why',\n",
       " '▁such',\n",
       " '▁optimism',\n",
       " '▁for',\n",
       " '▁some',\n",
       " '▁and',\n",
       " '▁pes',\n",
       " 'sim',\n",
       " 'ism',\n",
       " '▁for',\n",
       " '▁others',\n",
       " '?',\n",
       " '</s>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "def get_attn_weights():\n",
    "\tsources = []\n",
    "\tpreds = []\n",
    "\tattn_weights = []\n",
    "\tfor idx in rand_idxs:\n",
    "\t\tsource = short_examples[idx][0].unsqueeze(0)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tdecoder_outputs, _, decoder_attn = encoder_decoder(source, input_lengths=torch.tensor([source.shape[1]]), return_attention_weights=True)\n",
    "\t\t\tpred = decoder_outputs.argmax(dim=-1)[0]\n",
    "\t\t\tprint(f'source: {source_tokenizer.decode(source[0])}')\n",
    "\t\t\tprint(f'target: {target_tokenizer.decode(pred)}')\n",
    "\t\tsources.append(source)\n",
    "\t\tpreds.append(pred)\n",
    "\t\tattn_weights.append(decoder_attn)\n",
    "\treturn sources, preds, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:22.234531Z",
     "start_time": "2025-06-15T18:35:22.231331Z"
    }
   },
   "id": "36f8da6ab595c013",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "sources, preds, attn_weights = get_attn_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:35:22.929050Z",
     "start_time": "2025-06-15T18:35:22.239937Z"
    }
   },
   "id": "89ffce707d42c649",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: But why such optimism for some and pessimism for others?\n",
      "target: Mais pourquoi un tel optimisme pour certains et le pessimisme pour les autres?\n",
      "source: Regulatory authority over phone calls belongs to the Federal Communications Commission, not the FAA.\n",
      "target: L'autorité réglementaire sur les appels téléphoniques appartient à la Commission fédérale des communications et non à la FAA.\n",
      "source: They don't want us to dictate to them what makes them profitable.\n",
      "target: Ils ne veulent pas que nous leur dictions ce qui les rend rentables.\n",
      "source: The cinema was ventilated and everyone returned in good order.\n",
      "target: Le cinéma a été ventilé et tous les gens sont revenus dans l'ordre.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1x1 grid of subplots\n",
    "fig = make_subplots(\n",
    "\trows=1,\n",
    "\tcols=1,\n",
    "    # horizontal_spacing=0.09,\n",
    "    # vertical_spacing=0.09\n",
    ")\n",
    "\n",
    "# Add heatmaps to the grid\n",
    "row_col_idx_map = {\n",
    "    (0, 0): 0,\n",
    "    (1, 0): 1,\n",
    "    (0, 1): 2,\n",
    "    (1, 1): 3\n",
    "}\n",
    "for i in range(1):\n",
    "\tfor j in range(1):\n",
    "\t\tidx = row_col_idx_map[(i, j)]\n",
    "\t\tx_labels = [source_tokenizer.processor.id_to_piece(x.item()) for x in sources[idx][0]]\n",
    "\t\ty_labels = [target_tokenizer.processor.id_to_piece(x.item()) for x in preds[idx]]\n",
    "\n",
    "\n",
    "\t\t# need to escape <s> and </s>\n",
    "\t\tx_labels = [x if x not in ('<s>', '</s>') else ('&lt;s&gt;' if x == '<s>' else ' &lt;/s&gt;') for x in x_labels]\n",
    "\t\ty_labels = [x if x not in ('<s>', '</s>') else ('&lt;s&gt;' if x == '<s>' else ' &lt;/s&gt;') for x in y_labels]\n",
    "\n",
    "\t\tz_data = attn_weights[idx][0]\n",
    "\t\tx_indices = list(range(len(x_labels)))\n",
    "\t\ty_indices = list(range(len(y_labels)))\n",
    "\n",
    "\t\tfig.add_trace(\n",
    "\t\t\tgo.Heatmap(\n",
    "\t\t\t\tz=z_data,\n",
    "\t\t\t\tcolorscale=\"Blues\",\n",
    "\t\t\t\tzmin=0,\n",
    "\t\t\t\tzmax=1,\n",
    "\t\t\t\tshowscale=False\n",
    "\t\t\t),\n",
    "\t\t\trow=i + 1, col=j + 1\n",
    "\t\t)\n",
    "\t\tfig.update_yaxes(\n",
    "\t\t\tautorange='reversed',\n",
    "\t\t\trow=i + 1,\n",
    "\t\t\tcol=j + 1,\n",
    "\t\t\ttickmode='array',\n",
    "\t\t\ttickvals=y_indices,\n",
    "\t\t\tticktext=y_labels,\n",
    "\t\t)\n",
    "\t\tfig.update_xaxes(\n",
    "\t\t\ttickangle=45,\n",
    "\t\t\trow=i + 1,\n",
    "\t\t\tcol=j + 1,\n",
    "\t\t\ttickmode='array',\n",
    "\t\t\ttickvals=x_indices,\n",
    "\t\t\tticktext=x_labels,\n",
    "\t\t)\n",
    "\n",
    "\tfig.update_layout(\n",
    "\theight=400,\n",
    "\twidth=None,\n",
    "\tcoloraxis=dict(\n",
    "\t\tcolorscale=\"Blues\"  # Set your desired colorscale here\n",
    "\t),\n",
    "\tautosize=True,\n",
    "\tplot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area\n",
    "\tpaper_bgcolor='rgba(0,0,0,0)',  # Transparent outer background\n",
    "\tfont=dict(color='black'),  # Set tick label color for visibility\n",
    "\tmargin=dict(t=0, r=0)\n",
    "\t)\n",
    "\n",
    "\t# Display the plot\n",
    "\t#fig.show()\n",
    "\tfig.write_json('/Users/adam.amster/aamster.github.io/assets/plotly/2025-04-13-sequence_to_sequence_translation_2/attention_weights.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-15T18:43:29.070151Z",
     "start_time": "2025-06-15T18:43:29.043071Z"
    }
   },
   "id": "694788780c617af4",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
