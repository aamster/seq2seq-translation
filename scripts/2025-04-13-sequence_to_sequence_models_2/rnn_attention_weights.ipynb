{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:00.562507Z",
     "start_time": "2025-07-05T15:03:00.559131Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from seq2seq_translation.datasets.datasets import LanguagePairsDatasets\n",
    "from seq2seq_translation.sentence_pairs_dataset import SentencePairsDataset\n",
    "from seq2seq_translation.tokenization.sentencepiece_tokenizer import SentencePieceTokenizer\n",
    "from seq2seq_translation.run import _fix_model_state_dict"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "torch.random.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:00.583914Z",
     "start_time": "2025-07-05T15:03:00.580781Z"
    }
   },
   "id": "5176f06e6aa5f6b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "source_tokenizer = SentencePieceTokenizer(model_prefix='/Users/adam.amster/Downloads/30000/en30000')\n",
    "target_tokenizer = SentencePieceTokenizer(model_prefix='/Users/adam.amster/Downloads/30000/fr30000')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:00.615739Z",
     "start_time": "2025-07-05T15:03:00.598158Z"
    }
   },
   "id": "5942c27f80686dae",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ['DEVICE'] = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:00.629506Z",
     "start_time": "2025-07-05T15:03:00.627985Z"
    }
   },
   "id": "d49393923246e455",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def construct_test_dset():\n",
    "\ttest_datasets = LanguagePairsDatasets(\n",
    "\t\t\tdata_path=Path('/Users/adam.amster/seq2seq_translation/datasets/wmt14_test/wmt___wmt14/fr-en/0.0.0/b199e406369ec1b7634206d3ded5ba45de2fe696/wmt14-test.arrow'),\n",
    "\t\t\tsource_lang='en',\n",
    "\t\t\ttarget_lang='fr',\n",
    "\t\t\tis_test=True\n",
    "\t)\n",
    "\t\n",
    "\ttest_dset = SentencePairsDataset(\n",
    "\t\tdatasets=test_datasets,\n",
    "\t\tidxs=np.arange(len(test_datasets)),\n",
    "\t\tsource_tokenizer=source_tokenizer,\n",
    "\t\ttarget_tokenizer=target_tokenizer,\n",
    "\t\tmax_length=None,\n",
    "        eos_token_id=source_tokenizer.eot_idx,\n",
    "        pad_token_id=source_tokenizer.pad_idx,\n",
    "        add_bos_token_id=True,\n",
    "        bos_token_id=source_tokenizer.processor.bos_id()\n",
    "\t)\n",
    "\treturn test_dset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:00.643727Z",
     "start_time": "2025-07-05T15:03:00.641505Z"
    }
   },
   "id": "fd372758075226e6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "test_dset = construct_test_dset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:00.745236Z",
     "start_time": "2025-07-05T15:03:00.655854Z"
    }
   },
   "id": "92f8ac9a2a42c9fc",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "from seq2seq_translation.models.attention.attention import AttentionType\n",
    "from seq2seq_translation.models.rnn import EncoderRNN, AttnDecoderRNN, EncoderDecoderRNN\n",
    "\n",
    "\n",
    "def construct_model_attention():\n",
    "\tencoder = EncoderRNN(\n",
    "\t\tinput_size=source_tokenizer.processor.vocab_size(),\n",
    "\t\thidden_size=1000,\n",
    "\t\tbidirectional=True,\n",
    "\t\tpad_idx=source_tokenizer.processor.pad_id(),\n",
    "\t\tembedding_dim=1000,\n",
    "\t\tnum_layers=4,\n",
    "\t)\n",
    "\n",
    "\tdecoder = AttnDecoderRNN(\n",
    "\t\thidden_size=1000,\n",
    "\t\tattention_size=1000,\n",
    "\t\toutput_size=target_tokenizer.processor.vocab_size(),\n",
    "\t\tencoder_bidirectional=True,\n",
    "\t\tmax_len=200,\n",
    "\t\tattention_type=AttentionType.CosineSimilarityAttention,\n",
    "\t\tencoder_output_size=encoder.output_size,\n",
    "\t\tpad_idx=source_tokenizer.processor.pad_id(),\n",
    "\t\tnum_embeddings=target_tokenizer.processor.vocab_size(),\n",
    "\t\tsos_token_id=source_tokenizer.processor.bos_id(),\n",
    "\t\tembedding_dim=1000,\n",
    "\t\tnum_layers=4,\n",
    "\t\teos_token_id=target_tokenizer.processor.eos_id()\n",
    "\t)\n",
    "\t\n",
    "\tencoder.load_state_dict(\n",
    "\t\t_fix_model_state_dict(torch.load('/Users/adam.amster/Downloads/attention/encoder.pt', map_location='cpu'))\n",
    "\t)\n",
    "\tdecoder.load_state_dict(\n",
    "\t\t_fix_model_state_dict(torch.load('/Users/adam.amster/Downloads/attention/decoder.pt', map_location='cpu'))\n",
    "\t)\n",
    "\tencoder_decoder = EncoderDecoderRNN(\n",
    "\t\tencoder=encoder,\n",
    "\t\tdecoder=decoder,\n",
    "\t)\n",
    "\tencoder_decoder.eval()\n",
    "\treturn encoder_decoder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:00.764739Z",
     "start_time": "2025-07-05T15:03:00.761245Z"
    }
   },
   "id": "6cdd466198dd3557",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "encoder_decoder = construct_model_attention()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:02.058800Z",
     "start_time": "2025-07-05T15:03:00.777043Z"
    }
   },
   "id": "ad0b0f1e96d6b18",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "def get_test_dset_examples():\n",
    "\tshort = [x for x in test_dset if  10 <= len(x[0]) <= 20]\n",
    "\treturn short"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:02.072168Z",
     "start_time": "2025-07-05T15:03:02.069834Z"
    }
   },
   "id": "f153cd66edc93261",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "short_examples = get_test_dset_examples()\n",
    "rand_idxs = torch.randint(low=0, high=len(short_examples), size=(4,))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:02.519909Z",
     "start_time": "2025-07-05T15:03:02.100181Z"
    }
   },
   "id": "878901c00a028194",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:02.537188Z",
     "start_time": "2025-07-05T15:03:02.532612Z"
    }
   },
   "cell_type": "code",
   "source": "[source_tokenizer.processor.id_to_piece(x.item()) for x in short_examples[rand_idxs[0]][0]]",
   "id": "8728f5e8f1f60d9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁But',\n",
       " '▁why',\n",
       " '▁such',\n",
       " '▁optimism',\n",
       " '▁for',\n",
       " '▁some',\n",
       " '▁and',\n",
       " '▁pes',\n",
       " 'sim',\n",
       " 'ism',\n",
       " '▁for',\n",
       " '▁others',\n",
       " '?',\n",
       " '</s>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "def get_attn_weights():\n",
    "\tsources = []\n",
    "\tpreds = []\n",
    "\tattn_weights = []\n",
    "\tfor idx in rand_idxs:\n",
    "\t\tsource = short_examples[idx][0].unsqueeze(0)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tdecoder_outputs, _, decoder_attn = encoder_decoder(source, input_lengths=torch.tensor([source.shape[1]]), return_attention_weights=True)\n",
    "\t\t\tpred = decoder_outputs.argmax(dim=-1)[0]\n",
    "\t\t\tprint(f'source: {source_tokenizer.decode(source[0])}')\n",
    "\t\t\tprint(f'target: {target_tokenizer.decode(pred)}')\n",
    "\t\tsources.append(source)\n",
    "\t\tpreds.append(pred)\n",
    "\t\tattn_weights.append(decoder_attn)\n",
    "\treturn sources, preds, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:02.555031Z",
     "start_time": "2025-07-05T15:03:02.552251Z"
    }
   },
   "id": "36f8da6ab595c013",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "sources, preds, attn_weights = get_attn_weights()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T15:03:03.245707Z",
     "start_time": "2025-07-05T15:03:02.567837Z"
    }
   },
   "id": "89ffce707d42c649",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: But why such optimism for some and pessimism for others?\n",
      "target: Mais pourquoi un tel optimisme pour certains et le pessimisme pour les autres?\n",
      "source: Regulatory authority over phone calls belongs to the Federal Communications Commission, not the FAA.\n",
      "target: L'autorité réglementaire sur les appels téléphoniques appartient à la Commission fédérale des communications et non à la FAA.\n",
      "source: They don't want us to dictate to them what makes them profitable.\n",
      "target: Ils ne veulent pas que nous leur dictions ce qui les rend rentables.\n",
      "source: The cinema was ventilated and everyone returned in good order.\n",
      "target: Le cinéma a été ventilé et tous les gens sont revenus dans l'ordre.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "import math, numpy as np, plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# ───────────  STYLE CONSTANTS  ───────────\n",
    "ROW_H_PX   = 22          # px between token rows\n",
    "FONT_SIZE  = 14          # pt\n",
    "COL_GAP    = 1.8         # x-distance between columns\n",
    "LINE_ALPHA = 0.45        # line opacity\n",
    "LW_SCALE   = 4           # max line width multiplier\n",
    "THRESH     = 0.1        # skip weights < THRESH\n",
    "# ─────────────────────────────────────────\n",
    "\n",
    "\n",
    "# ─────────────────────  ONE HEAD  →  ONE SUBPLOT  ──────────────────────\n",
    "def add_arc_subplot(fig, row, col,\n",
    "                    weights, left_tok, right_tok,\n",
    "                    *, show=True):\n",
    "    \"\"\"\n",
    "    Draw vertical/vertical arc diagram for a single head in subplot (row, col).\n",
    "\n",
    "    * first token in each list is at the TOP row (y = 0)\n",
    "    * one blue line per weight ≥ THRESH\n",
    "    * shorter column simply ends – no phantom lines\n",
    "    \"\"\"\n",
    "    T_q, T_k  = weights.shape\n",
    "    max_len   = max(T_q, T_k)\n",
    "    y_left    = np.arange(T_q) * ROW_H_PX\n",
    "    y_right   = np.arange(T_k) * ROW_H_PX\n",
    "    ymax      = (max_len - 1) * ROW_H_PX + ROW_H_PX / 2\n",
    "\n",
    "    # 1️⃣ lines under the text\n",
    "    for i in range(T_q):\n",
    "        for j in range(T_k):\n",
    "            w = float(weights[i, j])\n",
    "            if w < THRESH:\n",
    "                continue\n",
    "            # coordinates for a *dense* line -----------------------------\n",
    "            n_pts   = 20                                  # ← tweak if needed\n",
    "            xs      = np.linspace(0.15, COL_GAP - 0.15, n_pts)\n",
    "            ys      = np.linspace(y_left[i], y_right[j], n_pts)\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=xs, y=ys,\n",
    "\n",
    "                    # draw the blue segment\n",
    "                    mode='lines+markers',\n",
    "                    line=dict(width=LW_SCALE * w,\n",
    "                              color=f'rgba(65,105,225,{LINE_ALPHA})'),\n",
    "\n",
    "                    # invisible markers sitting *on* the line\n",
    "                    marker=dict(size=8, color='rgba(0,0,0,0)'),\n",
    "\n",
    "                    # one tooltip for all points\n",
    "                    hoverinfo='text',\n",
    "                    hovertext=[(\n",
    "                        f\"src: {left_tok[i]}\"\n",
    "                        f\"<br>tgt: {right_tok[j]}\"\n",
    "                        f\"<br>weight: {w:.3f}\"\n",
    "                    )] * n_pts,\n",
    "                    hovertemplate=\"%{hovertext}<extra></extra>\",\n",
    "\n",
    "                    showlegend=False,\n",
    "                    visible=show),\n",
    "                row=row, col=col)\n",
    "\n",
    "\n",
    "    # 2️⃣ token labels over the lines\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.zeros(T_q), y=y_left,\n",
    "                   mode='text', text=left_tok,\n",
    "                   textfont=dict(size=FONT_SIZE, color='black'),\n",
    "                   textposition='middle right',\n",
    "                   showlegend=False, visible=show),\n",
    "        row=row, col=col)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.full(T_k, COL_GAP), y=y_right,\n",
    "                   mode='text', text=right_tok,\n",
    "                   textfont=dict(size=FONT_SIZE, color='black'),\n",
    "                   textposition='middle left',\n",
    "                   showlegend=False, visible=show),\n",
    "        row=row, col=col)\n",
    "\n",
    "    # 3️⃣ axes\n",
    "    fig.update_xaxes(visible=False, range=[-0.5, COL_GAP + .5], row=row, col=col)\n",
    "    fig.update_yaxes(visible=False, range=[-ROW_H_PX / 2, ymax],\n",
    "                     autorange='reversed', row=row, col=col)\n",
    "\n",
    "\n",
    "# ─────────────────────────────  DRIVER  ────────────────────────────────\n",
    "def plot_attn_weights(base_output_dir: Path, n_columns: int = 3):\n",
    "\t\"\"\"\n",
    "\tBuild full multi-head / multi-layer arc-diagram figure and write to HTML+JSON.\n",
    "\t\"\"\"\n",
    "\tsources, preds, attn_weights = get_attn_weights()\n",
    "\n",
    "\tfor idx in range(1):\n",
    "\t\tn_rows = 1\n",
    "\n",
    "\t\tfig = make_subplots(\n",
    "\t\t\trows=1, cols=1,\n",
    "\t\t\thorizontal_spacing=.09, vertical_spacing=.03)\n",
    "\n",
    "\t\tright = [source_tokenizer.processor.id_to_piece(x.item()) for x in sources[idx][0]]\n",
    "\t\tleft = [target_tokenizer.processor.id_to_piece(x.item()) for x in preds[idx]]\n",
    "\n",
    "\t\t# need to escape <s> and </s>\n",
    "\t\tright = [x if x not in ('<s>', '</s>') else ('&lt;s&gt;' if x == '<s>' else ' &lt;/s&gt;') for x in right]\n",
    "\t\tleft = [x if x not in ('<s>', '</s>') else ('&lt;s&gt;' if x == '<s>' else ' &lt;/s&gt;') for x in left]\n",
    "\n",
    "\t\t# build all subplots & store trace ids per layer\n",
    "\t\ttraces = []\n",
    "\t\tstart = len(fig.data)\n",
    "\n",
    "\t\t#print(ex, lay, hd, start)\n",
    "\t\tadd_arc_subplot(\n",
    "\t\t\tfig, row=1, col=1,\n",
    "\t\t\tweights=attn_weights[idx][0],\n",
    "\t\t\tleft_tok=left,\n",
    "\t\t\tright_tok=right,\n",
    "\t\t\tshow=True)\n",
    "\n",
    "\t\ttraces.extend(range(start, len(fig.data)))\n",
    "\n",
    "\t\tmax_tok   = max(len(left), len(right))\n",
    "\t\tsubplot_h = max_tok * ROW_H_PX + 40\n",
    "\n",
    "\t\tfig.update_layout(\n",
    "\t\t\tautosize=False,\n",
    "\t\t\twidth  = n_columns * 320,\n",
    "\t\t\theight = n_rows * subplot_h + 120,\n",
    "\t\t\tmargin=dict(t=20,l=20,r=20,b=60),\n",
    "\t\t\tfont=dict(size=FONT_SIZE, color='black'),\n",
    "\t\t\tplot_bgcolor='rgba(0,0,0,0)',\n",
    "\t\t\tpaper_bgcolor='rgba(0,0,0,0)',\n",
    "\t\t)\n",
    "\t\tfor ann in fig.layout.annotations:\n",
    "\t\t\tann.font.update(size=FONT_SIZE+2, color='black')\n",
    "\n",
    "\t\tbase = (f'{base_output_dir}/'\n",
    "\t\t\t\tf'rnn_attention_weights_{idx}')\n",
    "\t\tfig.write_json(base+'.json')\n",
    "\t\tfig.write_html(base+'.html')\n",
    "plot_attn_weights(base_output_dir=Path('/Users/adam.amster/aamster.github.io/assets/plotly/2025-04-13-sequence_to_sequence_translation_2/'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-05T18:26:29.907521Z",
     "start_time": "2025-07-05T18:26:29.113405Z"
    }
   },
   "id": "694788780c617af4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: But why such optimism for some and pessimism for others?\n",
      "target: Mais pourquoi un tel optimisme pour certains et le pessimisme pour les autres?\n",
      "source: Regulatory authority over phone calls belongs to the Federal Communications Commission, not the FAA.\n",
      "target: L'autorité réglementaire sur les appels téléphoniques appartient à la Commission fédérale des communications et non à la FAA.\n",
      "source: They don't want us to dictate to them what makes them profitable.\n",
      "target: Ils ne veulent pas que nous leur dictions ce qui les rend rentables.\n",
      "source: The cinema was ventilated and everyone returned in good order.\n",
      "target: Le cinéma a été ventilé et tous les gens sont revenus dans l'ordre.\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq_translation",
   "language": "python",
   "name": "seq2seq_translation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
