{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:13.700979Z",
     "start_time": "2025-06-18T15:56:09.351805Z"
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from seq2seq_translation.datasets.datasets import LanguagePairsDatasets\n",
    "from seq2seq_translation.sentence_pairs_dataset import SentencePairsDataset\n",
    "from seq2seq_translation.tokenization.sentencepiece_tokenizer import SentencePieceTokenizer\n",
    "from seq2seq_translation.run import _fix_model_state_dict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "torch.random.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:13.707697Z",
     "start_time": "2025-06-18T15:56:13.704248Z"
    }
   },
   "id": "5176f06e6aa5f6b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "source_tokenizer = SentencePieceTokenizer(model_prefix='/Users/adam.amster/seq2seq_translation/tokenizer/30000/en')\n",
    "target_tokenizer = SentencePieceTokenizer(model_prefix='/Users/adam.amster/seq2seq_translation/tokenizer/30000/fr')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:13.756044Z",
     "start_time": "2025-06-18T15:56:13.740062Z"
    }
   },
   "id": "5942c27f80686dae",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ['DEVICE'] = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:13.766503Z",
     "start_time": "2025-06-18T15:56:13.764673Z"
    }
   },
   "id": "d49393923246e455",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def construct_test_dset():\n",
    "\ttest_datasets = LanguagePairsDatasets(\n",
    "\t\t\tout_dir=Path('/Users/adam.amster/seq2seq_translation/datasets/wmt14_test'),\n",
    "\t\t\tsource_lang='en',\n",
    "\t\t\ttarget_lang='fr',\n",
    "\t\t\tis_test=True\n",
    "\t)\n",
    "\t\n",
    "\ttest_dset = SentencePairsDataset(\n",
    "\t\tdatasets=test_datasets,\n",
    "\t\tidxs=np.arange(len(test_datasets)),\n",
    "\t\tsource_tokenizer=source_tokenizer,\n",
    "\t\ttarget_tokenizer=target_tokenizer,\n",
    "\t\tmax_length=None,\n",
    "        eos_token_id=source_tokenizer.eot_idx,\n",
    "        pad_token_id=source_tokenizer.pad_idx,\n",
    "\t)\n",
    "\treturn test_dset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:13.773019Z",
     "start_time": "2025-06-18T15:56:13.770740Z"
    }
   },
   "id": "fd372758075226e6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "test_dset = construct_test_dset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:15.196048Z",
     "start_time": "2025-06-18T15:56:13.777657Z"
    }
   },
   "id": "92f8ac9a2a42c9fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e3a8636ffa2470897a1e4ff13fdf396"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "from seq2seq_translation.config.transformer_config import TransformerConfig\n",
    "import json\n",
    "from seq2seq_translation.models.transformer.encoder_decoder import EncoderDecoderTransformer\n",
    "\n",
    "\n",
    "def construct_model():\n",
    "\twith open('/Users/adam.amster/Downloads/train_config-2.json') as f:\n",
    "\t\tconfig = json.load(f)\n",
    "\tconfig = TransformerConfig.model_validate(config)\n",
    "\n",
    "\tmodel = EncoderDecoderTransformer(\n",
    "\t\tn_attention_heads=config.n_head,\n",
    "\t\tn_layers=config.num_layers,\n",
    "\t\tvocab_size=source_tokenizer.vocab_size,\n",
    "\t\td_model=config.d_model,\n",
    "\t\tblock_size=config.max_input_length,\n",
    "\t\tfeedforward_hidden_dim=config.feedforward_hidden_dim,\n",
    "\t\tsos_token_id=source_tokenizer.processor.bos_id(),\n",
    "\t\teos_token_id=source_tokenizer.processor.eos_id(),\n",
    "\t\tpad_token_id=source_tokenizer.processor.pad_id(),\n",
    "\t\tnorm_first=config.norm_first,\n",
    "\t\tmlp_activation=config.activation,\n",
    "\t\tpositional_encoding_type=config.positional_encoding_type,\n",
    "\t)\n",
    "\n",
    "\tmodel.load_state_dict(\n",
    "\t\t_fix_model_state_dict(torch.load('/Users/adam.amster/Downloads/ckpt.pt', map_location='cpu')[\"model\"])\n",
    "\t)\n",
    "\n",
    "\tmodel.eval()\n",
    "\treturn model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:15.206709Z",
     "start_time": "2025-06-18T15:56:15.202209Z"
    }
   },
   "id": "6cdd466198dd3557",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "encoder_decoder = construct_model()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:16.031530Z",
     "start_time": "2025-06-18T15:56:15.211556Z"
    }
   },
   "id": "ad0b0f1e96d6b18",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def get_test_dset_examples():\n",
    "\tshort = [x for x in test_dset if  9 <= len(x[0]) <= 19]\n",
    "\treturn short"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:16.041146Z",
     "start_time": "2025-06-18T15:56:16.038517Z"
    }
   },
   "id": "f153cd66edc93261",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "short_examples = get_test_dset_examples()\n",
    "rand_idxs = [592, 533, 463, 187]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:16.451579Z",
     "start_time": "2025-06-18T15:56:16.047089Z"
    }
   },
   "id": "878901c00a028194",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:16.460267Z",
     "start_time": "2025-06-18T15:56:16.458072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class AttnType(Enum):\n",
    "    ENCODER_SELF = 'ENCODER_SELF'\n",
    "    DECODER_SELF = 'DECODER_SELF'\n",
    "    DECODER_CROSS = 'DECODER_CROSS'"
   ],
   "id": "f6519b2cbd3b0a69",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def get_attn_weights(attention_type: AttnType):\n",
    "\tsources = []\n",
    "\tpreds = []\n",
    "\tattn_weights = []\n",
    "\tfor idx in rand_idxs:\n",
    "\t\tsource = short_examples[idx][0].unsqueeze(0)\n",
    "\t\ttarget = short_examples[idx][1].unsqueeze(0)\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tif attention_type == AttnType.ENCODER_SELF:\n",
    "\t\t\t\tattention_weights = encoder_decoder.encoder(source, src_key_padding_mask=torch.ones_like(source, dtype=torch.bool),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\treturn_attention_weights=True)\n",
    "\t\t\telif attention_type == AttnType.DECODER_CROSS:\n",
    "\t\t\t\t_, _, attention_weights = encoder_decoder.generate(\n",
    "\t\t\t\t\tsrc=source,\n",
    "\t\t\t\t\ttop_k=1,\n",
    "                    return_cross_attention_weights=True\n",
    "\t\t\t\t)\n",
    "\t\t\tpred, _ = encoder_decoder.generate(\n",
    "\t\t\t\tsrc=source,\n",
    "\t\t\t\ttop_k=1,\n",
    "\t\t\t)\n",
    "\t\t\tprint(f'source: {source_tokenizer.decode(source[0])}')\n",
    "\t\t\tprint(f'target: {target_tokenizer.decode(target[0])}')\n",
    "\t\t\tprint(f'pred: {target_tokenizer.decode(pred)}')\n",
    "\t\tsources.append(source)\n",
    "\t\tpreds.append(pred)\n",
    "\t\tattn_weights.append(attention_weights)\n",
    "\treturn sources, preds, attn_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:16.469513Z",
     "start_time": "2025-06-18T15:56:16.466033Z"
    }
   },
   "id": "36f8da6ab595c013",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "def plot_attn_weights(attn_type: AttnType):\n",
    "\tsources, preds, attn_weights = get_attn_weights(attention_type=attn_type)\n",
    "\n",
    "\tfor idx in range(len(sources)):\n",
    "\t\tn_layers = len(attn_weights[idx])\n",
    "\t\tn_heads = attn_weights[idx][0].shape[1]\n",
    "\n",
    "\t\tn_rows = math.ceil(n_heads/3)\n",
    "\t\tn_cols = 3\n",
    "\n",
    "\t\tfig = make_subplots(\n",
    "\t\t\trows=n_rows,\n",
    "\t\t\tcols=n_cols,\n",
    "\t\t\thorizontal_spacing=0.09,\n",
    "\t\t\tvertical_spacing=0.12,\n",
    "\t\t\tsubplot_titles=[f'Head {h+1}' for h in range(n_heads)]\n",
    "\t\t)\n",
    "\n",
    "\t\tif attn_type == AttnType.ENCODER_SELF:\n",
    "\t\t\tx_labels = [source_tokenizer.processor.id_to_piece(x.item()) for x in sources[idx][0]]\n",
    "\t\t\ty_labels = [source_tokenizer.processor.id_to_piece(x.item()) for x in sources[idx][0]]\n",
    "\t\telif attn_type == AttnType.DECODER_SELF:\n",
    "\t\t\tx_labels = [target_tokenizer.processor.id_to_piece(x.item()) for x in preds[idx][0]]\n",
    "\t\t\ty_labels = [target_tokenizer.processor.id_to_piece(x.item()) for x in preds[idx][0]]\n",
    "\t\telse:\n",
    "\t\t\tx_labels = [source_tokenizer.processor.id_to_piece(x.item()) for x in sources[idx][0]]\n",
    "\t\t\ty_labels = [target_tokenizer.processor.id_to_piece(x.item()) for x in preds[idx][0]]\n",
    "\n",
    "\t\t# need to escape <s> and </s>\n",
    "\t\tx_labels = [x if x not in ('<s>', '</s>') else ('&lt;s&gt;' if x == '<s>' else ' &lt;/s&gt;') for x in x_labels]\n",
    "\t\ty_labels = [x if x not in ('<s>', '</s>') else ('&lt;s&gt;' if x == '<s>' else ' &lt;/s&gt;') for x in y_labels]\n",
    "\n",
    "\t\tfor layer in range(n_layers):\n",
    "\t\t\trow_idx = 0\n",
    "\t\t\tcol_idx = 0\n",
    "\t\t\tfor head in range(n_heads):\n",
    "\t\t\t\tz_data = attn_weights[idx][layer][0, head]\n",
    "\t\t\t\tx_indices = list(range(len(x_labels)))\n",
    "\t\t\t\ty_indices = list(range(len(y_labels)))\n",
    "\n",
    "\t\t\t\tfig.add_trace(\n",
    "\t\t\t\t\tgo.Heatmap(\n",
    "\t\t\t\t\t\tz=z_data,\n",
    "\t\t\t\t\t\tcolorscale=\"Blues\",\n",
    "\t\t\t\t\t\tzmin=0,\n",
    "\t\t\t\t\t\tzmax=1,\n",
    "\t\t\t\t\t\tshowscale=False,\n",
    "\t\t\t\t\t\tvisible=layer == 0,\n",
    "\t\t\t\t\t),\n",
    "\t\t\t\t\trow=row_idx+1,\n",
    "\t\t\t\t\tcol=col_idx+1,\n",
    "\t\t\t\t)\n",
    "\t\t\t\tfig.update_yaxes(\n",
    "\t\t\t\t\tautorange='reversed',\n",
    "\t\t\t\t\trow=row_idx+1,\n",
    "\t\t\t\t\tcol=col_idx + 1,\n",
    "\t\t\t\t\ttickmode='array',\n",
    "\t\t\t\t\ttickvals=y_indices,\n",
    "\t\t\t\t\tticktext=y_labels\n",
    "\t\t\t\t)\n",
    "\t\t\t\tfig.update_xaxes(\n",
    "\t\t\t\t\ttickangle=45,\n",
    "\t\t\t\t\trow=row_idx+1,\n",
    "\t\t\t\t\tcol=col_idx + 1,\n",
    "\t\t\t\t\ttickmode='array',\n",
    "\t\t\t\t\ttickvals=x_indices,\n",
    "\t\t\t\t\tticktext=x_labels\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\t\t\tcol_idx += 1\n",
    "\t\t\t\tif col_idx == n_cols:\n",
    "\t\t\t\t\trow_idx += 1\n",
    "\t\t\t\t\tcol_idx = 0\n",
    "\n",
    "\t\t# --- build slider steps\n",
    "\t\tsteps = []\n",
    "\t\tfor layer in range(n_layers):\n",
    "\t\t\tvis = [False]*(n_layers*n_heads)\n",
    "\t\t\tfor h in range(n_heads):\n",
    "\t\t\t\tvis[layer*n_heads + h] = True\n",
    "\t\t\tsteps.append(dict(label=f'Layer {layer+1}',\n",
    "\t\t\t\t\t\t\t  method='update',\n",
    "\t\t\t\t\t\t\t  args=[{'visible': vis}]))\n",
    "\n",
    "\t\tcell_px   = 23                     # tweak until it looks right\n",
    "\t\tfig.update_layout(\n",
    "\t\t\tcoloraxis=dict(\n",
    "\t\t\t\tcolorscale=\"Blues\"  # Set your desired colorscale here\n",
    "\t\t\t),\n",
    "\t\t\tautosize=False,\n",
    "\t\t\twidth  = n_cols * len(x_labels) * cell_px + 200,  # +200 for colour bar & margins\n",
    "\t\t\theight = n_rows * len(y_labels) * cell_px,\n",
    "\t\t\tplot_bgcolor='rgba(0,0,0,0)',  # Transparent plot area\n",
    "\t\t\tpaper_bgcolor='rgba(0,0,0,0)',  # Transparent outer background\n",
    "\t\t\tfont=dict(color='black'),  # Set tick label color for visibility\n",
    "\t\t\tmargin=dict(t=20, l=40, r=20, b=60),\n",
    "\t\t\tsliders=[dict(active=0, steps=steps, pad=dict(t=60, b=10))],\n",
    "\t\t)\n",
    "\n",
    "\t\t# Display the plot\n",
    "\t\t#fig.show()\n",
    "\n",
    "\t\tif attn_type == AttnType.ENCODER_SELF:\n",
    "\t\t\tattention_name = 'encoder_self_attention'\n",
    "\t\telif attn_type == AttnType.DECODER_CROSS:\n",
    "\t\t\tattention_name = 'cross_attention'\n",
    "\t\tfig.write_json(f'/Users/adam.amster/aamster.github.io/assets/plotly/2025-04-13-sequence_to_sequence_translation_2/multi_head_{attention_name}_weights_{idx}.json')\n",
    "\t\tfig.write_html(\n",
    "\t\t\tf'/Users/adam.amster/aamster.github.io/assets/plotly/2025-04-13-sequence_to_sequence_translation_2/multi_head_{attention_name}_weights_{idx}.html')\n",
    "plot_attn_weights(attn_type=AttnType.DECODER_CROSS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-18T15:57:50.317160Z",
     "start_time": "2025-06-18T15:57:47.168153Z"
    }
   },
   "id": "694788780c617af4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: But why such optimism for some and pessimism for others?\n",
      "target: Les raisons d'un tel optimisme, chez les uns, et pessimisme, chez les autres ?\n",
      "pred: Mais pourquoi un tel optimisme pour certains et le pessimisme pour d'autres?\n",
      "source: Regulatory authority over phone calls belongs to the Federal Communications Commission, not the FAA.\n",
      "target: Le pouvoir réglementaire concernant les téléphones portables appartient à la Federal Communications Commission et non à la FAA.\n",
      "pred: Le pouvoir de réglementation des appels téléphoniques appartient à la Commission fédérale des communications, et non à la FAA.\n",
      "source: They don't want us to dictate to them what makes them profitable.\n",
      "target: Elles ne veulent pas qu'on leur dise ce qui leur permettra d'être rentables.\n",
      "pred: Ils ne veulent pas que nous leur dictions ce qui les rend rentables.\n",
      "source: The cinema was ventilated and everyone returned in good order.\n",
      "target: La salle a été aérée et tout est rentré dans l'ordre.\n",
      "pred: Le cinéma a été ventilé et tout le monde est retourné en bon état.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:18.477524Z",
     "start_time": "2025-06-18T15:56:16.493172Z"
    }
   },
   "cell_type": "code",
   "source": "plot_attn_weights(attn_type=AttnType.ENCODER_SELF)",
   "id": "88e613a8aa05014d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: But why such optimism for some and pessimism for others?\n",
      "target: Les raisons d'un tel optimisme, chez les uns, et pessimisme, chez les autres ?\n",
      "pred: Mais pourquoi un tel optimisme pour certains et le pessimisme pour d'autres?\n",
      "source: Regulatory authority over phone calls belongs to the Federal Communications Commission, not the FAA.\n",
      "target: Le pouvoir réglementaire concernant les téléphones portables appartient à la Federal Communications Commission et non à la FAA.\n",
      "pred: Le pouvoir de réglementation des appels téléphoniques appartient à la Commission fédérale des communications, et non à la FAA.\n",
      "source: They don't want us to dictate to them what makes them profitable.\n",
      "target: Elles ne veulent pas qu'on leur dise ce qui leur permettra d'être rentables.\n",
      "pred: Ils ne veulent pas que nous leur dictions ce qui les rend rentables.\n",
      "source: The cinema was ventilated and everyone returned in good order.\n",
      "target: La salle a été aérée et tout est rentré dans l'ordre.\n",
      "pred: Le cinéma a été ventilé et tout le monde est retourné en bon état.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:27:02.797526Z",
     "start_time": "2025-06-18T16:21:27.368102Z"
    }
   },
   "cell_type": "code",
   "source": "plot_attn_weights(attn_type=AttnType.DECODER_CROSS)",
   "id": "66f5e518c551aaac",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplot_attn_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAttnType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDECODER_CROSS\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 7\u001B[0m, in \u001B[0;36mplot_attn_weights\u001B[0;34m(attn_type)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_attn_weights\u001B[39m(attn_type: AttnType):\n\u001B[0;32m----> 7\u001B[0m \tsources, preds, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[43mget_attn_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \t\u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(sources)):\n\u001B[1;32m     10\u001B[0m \t\tn_layers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(attn_weights[idx])\n",
      "Cell \u001B[0;32mIn[12], line 13\u001B[0m, in \u001B[0;36mget_attn_weights\u001B[0;34m(attention_type)\u001B[0m\n\u001B[1;32m     10\u001B[0m \t\t\t\tattention_weights \u001B[38;5;241m=\u001B[39m encoder_decoder\u001B[38;5;241m.\u001B[39mencoder(source, src_key_padding_mask\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mones_like(source, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mbool),\n\u001B[1;32m     11\u001B[0m \t\t\t\t\t\t\t\t\t\t\t\t\t\t\treturn_attention_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     12\u001B[0m \t\t\t\u001B[38;5;28;01melif\u001B[39;00m attention_type \u001B[38;5;241m==\u001B[39m AttnType\u001B[38;5;241m.\u001B[39mDECODER_CROSS:\n\u001B[0;32m---> 13\u001B[0m \t\t\t\t_, _, attention_weights \u001B[38;5;241m=\u001B[39m \u001B[43mencoder_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m\t\t\t\t\t\u001B[49m\u001B[43msrc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m\t\t\t\t\t\u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mreturn_cross_attention_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     17\u001B[0m \u001B[43m\t\t\t\t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \t\t\tpred, _ \u001B[38;5;241m=\u001B[39m encoder_decoder\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     19\u001B[0m \t\t\t\tsrc\u001B[38;5;241m=\u001B[39msource,\n\u001B[1;32m     20\u001B[0m \t\t\t\ttop_k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     21\u001B[0m \t\t\t)\n\u001B[1;32m     22\u001B[0m \t\t\t\u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msource: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msource_tokenizer\u001B[38;5;241m.\u001B[39mdecode(source[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/seq2seq translation/src/seq2seq_translation/models/transformer/encoder_decoder.py:132\u001B[0m, in \u001B[0;36mEncoderDecoderTransformer.generate\u001B[0;34m(self, src, x, encoder_out, temperature, top_k, max_new_tokens, return_cross_attention_weights)\u001B[0m\n\u001B[1;32m    129\u001B[0m logits, attention_weights \u001B[38;5;241m=\u001B[39m decoder_out\n\u001B[1;32m    131\u001B[0m \u001B[38;5;66;03m# extract just the new token cross attention\u001B[39;00m\n\u001B[0;32m--> 132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m(all_cross_attention_weights) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(attention_weights)):\n\u001B[1;32m    134\u001B[0m         all_cross_attention_weights[layer] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([all_cross_attention_weights[layer], attention_weights[layer][:, :, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m2\u001B[39m)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1103\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1065\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1235\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T15:56:22.006175Z",
     "start_time": "2025-06-18T15:56:22.004681Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f0c9bf663f12f36",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
